{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "208bac99-ed57-48ff-8645-7bffebf18609",
      "metadata": {
        "id": "208bac99-ed57-48ff-8645-7bffebf18609"
      },
      "source": [
        "# CSE5CV - Generative Adversarial Networks (GANs)\n",
        "\n",
        "In this lab we will explore two different Generative Adversarial Network (GAN) architectures pretrained on different datasets.\n",
        "\n",
        "Most of the code in this lab is provided to you.\n",
        "\n",
        "By the end of this lab, you should be able to:\n",
        "* Implement and run inference on a pre-trained GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Colab preparation\n",
        "\n",
        "Google Colab is a free online service for editing and running code in notebooks like this one. To get started, follow the steps below:\n",
        "\n",
        "1. Click the \"Copy to Drive\" button at the top of the page. This will open a new tab with the title \"Copy of...\". This is a copy of the lab notebook which is saved in your personal Google Drive. **Continue working in that copy, otherwise you will not be able to save your work**. You may close the original Colab page (the one which displays the \"Copy to Drive\" button).\n",
        "2. Run the code cell below to prepare the Colab coding environment by downloading sample files. Note that if you close this notebook and come back to work on it again later, you will need to run this cell again."
      ],
      "metadata": {
        "id": "qHrEAKS4h2Nm"
      },
      "id": "qHrEAKS4h2Nm"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ltu-cse5cv/cse5cv-labs.git\n",
        "%cd cse5cv-labs/Lab08"
      ],
      "metadata": {
        "id": "wM8UKEozh4MK"
      },
      "execution_count": null,
      "outputs": [],
      "id": "wM8UKEozh4MK"
    },
    {
      "cell_type": "markdown",
      "id": "23e84701-916c-4c66-9465-9a6f7ca10ec0",
      "metadata": {
        "id": "23e84701-916c-4c66-9465-9a6f7ca10ec0"
      },
      "source": [
        "## Packages\n",
        "In this lab we will be using the following packages:\n",
        "* *PyTorch* to work with pretrained GANs\n",
        "* *numpy* to represent image data\n",
        "* *matplotlib* for visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ade1a72d-8871-4161-acf2-87657ff3da4d",
      "metadata": {
        "id": "ade1a72d-8871-4161-acf2-87657ff3da4d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "670779a8-dac0-4c2d-ad5f-3ed21b881330",
      "metadata": {
        "id": "670779a8-dac0-4c2d-ad5f-3ed21b881330"
      },
      "source": [
        "Refer to the `Packages` notebook for more information on packages we have used before."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0505db54-e83a-4765-9243-e89bfa5d2639",
      "metadata": {
        "id": "0505db54-e83a-4765-9243-e89bfa5d2639"
      },
      "source": [
        "## Generative Adversarial Networks (GANs)\n",
        "You have covered GANs in detail in your lectures, but here we present a brief recap of what GANs are, and at a basic level, how they work.\n",
        "\n",
        "In previous labs you have seen examples of using a trained deep learning model to take some input and make some sort of prediction on that input, whether it be classification, detection or segmentation.\n",
        "\n",
        "Another application for deep learning is one where we want a network to *generate* synthetic data, that is, data that doesn't exist in the real world. Generative Adversarial Networks (GANs) have recently become very popular in this space.\n",
        "\n",
        "A GAN consists of two networks, a generator and discriminator, that both try to outperform one another. The task of the generator is to create synthetic data that look similar to the distribution of data in a training dataset, whilst the task of the discriminator is to predict whether data from the generator is real or synthesized.\n",
        "\n",
        "The end goal of the generator is to increase the error rate of the discriminator, meaning the discriminator can no longer reliably determine if data from the generator is real or synthetic. Once an acceptable error rate has been achieved (training is finished), the generator alone is used to generate synthetic data.\n",
        "\n",
        "There are many variations of GANs that exist that are trained in different ways and used to perform different tasks. Some GANs are used to generate synthetic images that resemble images from an existing dataset, some GANs are used to generate music matching the style of existing artists, others can apply the style of a dataset to new images, and some can even generate new images given a text description.\n",
        "\n",
        "Training GANs can be a lengthy and tricky process. Because of this, in this lab we will use two publicly available pre-trained GANs. These models are hosted on the [PyTorch hub](https://pytorch.org/hub/)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ff3071d-78eb-42f9-adf7-4f54a41ee8bb",
      "metadata": {
        "id": "6ff3071d-78eb-42f9-adf7-4f54a41ee8bb"
      },
      "source": [
        "# 1. PGAN\n",
        "The first GAN architecture we will explore is based on the [Progressive Growing of GANs for Improved Quality, Stability, and Variation](https://arxiv.org/abs/1710.10196) paper. The main contribution of this paper was a new training methodology for GANs to speed up training and improve stability."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9209e27-fd28-49c3-a686-73f08a6203eb",
      "metadata": {
        "id": "f9209e27-fd28-49c3-a686-73f08a6203eb"
      },
      "source": [
        "## 1.1 Pre-Trained Network\n",
        "We will be using a network that is pretrained on the [celebA HQ dataset](https://github.com/nperraud/download-celebA-HQ) \\(based on the [celebA dataset](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)\\). This dataset is comprised of face images of celebrities.\n",
        "\n",
        "This network is trained to generate synthetic images (of size 512x512px) that look similar to the data distribution in the celebA dataset. If you are interested, you can look at the [PGAN source code on GitHub](https://github.com/facebookresearch/pytorch_GAN_zoo/blob/master/models/progressive_gan.py).\n",
        "\n",
        "In the code cell below, we download a pre-trained PGAN model from the [PyTorch hub](https://pytorch.org/hub/). This size of this model is around 270MB, so it may take a few minutes to download for the first time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8776f0d-337f-4e26-a78d-bd368d890579",
      "metadata": {
        "id": "a8776f0d-337f-4e26-a78d-bd368d890579"
      },
      "outputs": [],
      "source": [
        "pgan = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'PGAN', model_name='celebAHQ-512', pretrained=True, useGPU=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4103ea2-3cb2-4054-a982-a1cb433491a8",
      "metadata": {
        "id": "c4103ea2-3cb2-4054-a982-a1cb433491a8"
      },
      "source": [
        "## 1.2 Model Input\n",
        "Now we have a network, how do we get it to generate images?\n",
        "\n",
        "In past labs, we needed to feed our networks some input which it used to generate predictions. In a similar way, for our GAN we need to feed it some input data, but in this case, that input data just consists of random noise!\n",
        "\n",
        "Our model produces 512x512px images. To generate those it requires a 512 dimensional vector filled with random values. Because we always need a batch dimension, this means the input to our network should be a *(**N**, 512)* dimensional tensor, where ***N*** = the number of images to generate (or our batch size).\n",
        "\n",
        "The PGAN implementation we are using includes a method to construct this random data (sampled from a normal distribution with mean=0, std=1). In the code cell below we create a *(4, 512)* dimensional tensor filled with random data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a88880e3-264c-4170-9112-1462594b7230",
      "metadata": {
        "id": "a88880e3-264c-4170-9112-1462594b7230"
      },
      "outputs": [],
      "source": [
        "noise, _ = pgan.buildNoiseData(n_samples=4)\n",
        "print(f'Shape of noise: {noise.shape}')\n",
        "print(f'Min/Max value of noise: {noise.min()}/{noise.max()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d87d976-c367-496f-94f1-dd1284b7383c",
      "metadata": {
        "id": "9d87d976-c367-496f-94f1-dd1284b7383c"
      },
      "source": [
        "## 1.3 Image Generation\n",
        "Now we have created input noise for our GAN, the next step is to pass it through our model to generate some images!\n",
        "\n",
        "Given the way the pre-trained model is implemented, to perform the forward pass through our model we need to call the *`test()`* method.\n",
        "\n",
        "In the code cell below, we generate 4 new images by passing the noise tensor to our GAN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a76b26bd-84d5-4928-8cc7-c3260e38b0d8",
      "metadata": {
        "tags": [],
        "id": "a76b26bd-84d5-4928-8cc7-c3260e38b0d8"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    generated_images = pgan.test(noise)\n",
        "print(f'Shape of output: {generated_images.shape}')\n",
        "print(f'Min/Max value of output: {generated_images.min()}/{generated_images.max()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1feabb74-7ed6-4779-9c44-125d2b6c4301",
      "metadata": {
        "id": "1feabb74-7ed6-4779-9c44-125d2b6c4301"
      },
      "source": [
        "## 1.4 Postprocessing and Visualization\n",
        "Now we have some generated images, all that remains is to do some postprocessing on the image data to get it to a *numpy* array, then visualize it!\n",
        "\n",
        "The postprocessing steps required per-image are to:\n",
        "* Get the values into the range [0, 1]\n",
        "* Convert the tensor to a *numpy* array\n",
        "* Transpose the array to get from ordering: CHW to HWC\n",
        "* Get values into the range [0, 255] with datatype uint8\n",
        "\n",
        "In the code cell below we provide the function *`display_image()`* that you have used in previous labs, and the function *`postprocess_image()`* which performs the steps outlined above. We then postprocess and display each generated image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3c821cf-2455-495d-b3e5-777374ec2f41",
      "metadata": {
        "id": "c3c821cf-2455-495d-b3e5-777374ec2f41"
      },
      "outputs": [],
      "source": [
        "def display_image(image, title=None):\n",
        "    fig, axes = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    if image.ndim == 2:\n",
        "        axes.imshow(image, cmap='gray', vmin=0, vmax=255)\n",
        "    else:\n",
        "        axes.imshow(image)\n",
        "\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def postprocess_image(tensor):\n",
        "    \"\"\"Postprocesses a generated image in a tensor, producing a numpy array\n",
        "\n",
        "    Args:\n",
        "        tensor (3xHxW torch.Tensor): The tensor to postprocess\n",
        "\n",
        "    Returns:\n",
        "        (HxWx3 ndarray): The processed tensor converted to a numpy array\n",
        "    \"\"\"\n",
        "    # Determine min/max values of tensor\n",
        "    low, high = float(tensor.min()), float(tensor.max())\n",
        "\n",
        "    # Subtract the minimum value from all values in tensor (making all values positive with min=0)\n",
        "    tensor = tensor - low\n",
        "\n",
        "    # Divide all values by the range of values in the tensor (making all values between [0, 1])\n",
        "    tensor = tensor / max(high - low, 1e-5)\n",
        "\n",
        "    # Convert tensor to numpy array\n",
        "    image = tensor.detach().cpu().numpy()\n",
        "\n",
        "    # Transpose to get ordering HWC\n",
        "    image = np.transpose(image, (1, 2, 0))\n",
        "\n",
        "    # Convert [0, 1] float32 into [0, 255] uint8\n",
        "    image = (image * 255).astype(np.uint8)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "# Postprocess and display the generated images\n",
        "for image_tensor in generated_images:\n",
        "    proc_image = postprocess_image(image_tensor)\n",
        "    display_image(proc_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05fcee76-df41-4b8e-a37a-08159c26aaf3",
      "metadata": {
        "id": "05fcee76-df41-4b8e-a37a-08159c26aaf3"
      },
      "source": [
        "Very cool results! You have just successfully used a GAN to take a vector filled with random noise, and generate synthetic images of people (none of these people exist in real life!). Whilst you may still see some artefacts in the images, this is still a very impressive result!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e3cc88c-6ea6-4992-84d6-2be120c29c13",
      "metadata": {
        "id": "7e3cc88c-6ea6-4992-84d6-2be120c29c13"
      },
      "source": [
        "## 1.5 Pulling it Together\n",
        "You've now seen all the bits and pieces involved to generate synthetic images of people using a GAN. To make this a bit easier to use, we will now write a function that will take a number of images to generate, then generate that many images!\n",
        "\n",
        "**Task**: Write a function *`generate_images`* that:\n",
        "* Takes a `model` and `num_images` as arguments\n",
        "* Creates a `num_images` noise vectors\n",
        "* Performs the forward pass through the model\n",
        "* Then for every generated image:\n",
        "    * Postprocesses and displays the image\n",
        "    \n",
        "At the end of the code cell is some code to test your solution. Try running this test a few times and see all the different types of faces you can generate (some of them are very convincingly real)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1365aa16-061c-4241-935a-7c5e1bee4489",
      "metadata": {
        "id": "1365aa16-061c-4241-935a-7c5e1bee4489"
      },
      "outputs": [],
      "source": [
        "# TODO: Your function here\n",
        "\n",
        "\n",
        "\n",
        "# Test your solution\n",
        "generate_images(pgan, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a80780f6-e088-4239-a65c-229ae7ee5eea",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "cellView": "form",
        "id": "a80780f6-e088-4239-a65c-229ae7ee5eea"
      },
      "outputs": [],
      "source": [
        "#@title Task solution\n",
        "\n",
        "def generate_images(model, num_images):\n",
        "    # Generate random noise\n",
        "    noise, _ = model.buildNoiseData(n_samples=num_images)\n",
        "\n",
        "    # Perform forward pass\n",
        "    with torch.no_grad():\n",
        "        generated_images = model.test(noise)\n",
        "\n",
        "    # Postprocess and display each generated image\n",
        "    for image_tensor in generated_images:\n",
        "        proc_image = postprocess_image(image_tensor)\n",
        "        display_image(proc_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c2841aa-6f0b-4d72-90f7-11d7cbbb71aa",
      "metadata": {
        "id": "3c2841aa-6f0b-4d72-90f7-11d7cbbb71aa"
      },
      "source": [
        "## 1.6 Digging Deeper\n",
        "We've seen that the generated images depend on the random noise vector fed to the GAN. How do small perturbations in the noise impact the generated image?\n",
        "\n",
        "In the code cell below, we generate a single random noise vector, then add a set of small perturbations to see how they impact the generated image.  \n",
        "If you are interested, feel free to add other values into the `perturbations` list to see how it impacts the generated image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fddeead-d94b-4e0a-aea2-0895a3753335",
      "metadata": {
        "id": "0fddeead-d94b-4e0a-aea2-0895a3753335"
      },
      "outputs": [],
      "source": [
        "# Set of perturbations to apply\n",
        "perturbations = [-0.2, -0.1, 0, 0.1, 0.2]\n",
        "\n",
        "# Generate random noise vector\n",
        "noise, _ = pgan.buildNoiseData(n_samples=1)\n",
        "\n",
        "# Create a tensor combining perturbations\n",
        "noise_tensor = torch.cat([noise + pert for pert in perturbations], dim=0)\n",
        "\n",
        "# Perform forward pass\n",
        "with torch.no_grad():\n",
        "    generated_images = pgan.test(noise_tensor)\n",
        "\n",
        "# Postprocess all images\n",
        "postprocessed_images = [postprocess_image(image_tensor) for image_tensor in generated_images]\n",
        "\n",
        "# Create a plot to display all images in a single row\n",
        "fig, axes = plt.subplots(nrows=1, ncols=len(perturbations), figsize=(19, 10))\n",
        "\n",
        "# Display images and set the titles to the perturbation applied\n",
        "for ax, image, pert in zip(axes, postprocessed_images, perturbations):\n",
        "    ax.imshow(image)\n",
        "    ax.set_title(pert)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cae19d83-0e5a-4cc7-85dd-d94e76fd9de0",
      "metadata": {
        "id": "cae19d83-0e5a-4cc7-85dd-d94e76fd9de0"
      },
      "source": [
        "**Question**: PGAN was trained to produce images for random noise vectors with 0 mean and a standard deviation of 1. The random noise that is generated by *`buildNoiseData()`* produces noise data in this range. Consider setting our perturbations between -50 and 50. This is clearly outside the trained area. Generally speaking Neural Networks only work in ranges they are trained for. A \"working\" GAN is one which produces somewhat realistic and highly varied images. So, what do you expect will happen if you set `perturbations = [-500, -50, 0.0, 50, 500]`?\n",
        "\n",
        "<details>\n",
        "<summary style='cursor:pointer;'><u>Answer</u></summary>\n",
        "Outside the trained region, there is no guarantee of much variation existing because it was never explicitly trained to make it so. If you run the above code, you'll see that there's not much difference between -50 and -500, even though we saw quite a noticable difference adding/subtracting 0.2. That is, the PGAN model just outputs the same image for large regions of space outside the trained region.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a026497-1d18-4c52-a8a6-bb4b089635ad",
      "metadata": {
        "id": "1a026497-1d18-4c52-a8a6-bb4b089635ad"
      },
      "source": [
        "# 2. DCGAN\n",
        "The second GAN architecture we will explore is based on the [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434) paper. The main contribution of this paper was the introduction of a specific CNN-based GAN architecture.\n",
        "\n",
        "The steps for setting this up are nearly identical to PGAN, so we wont spend too much time in this section."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f422330a-9259-4231-90d2-e4bca7534ff3",
      "metadata": {
        "id": "f422330a-9259-4231-90d2-e4bca7534ff3"
      },
      "source": [
        "## 2.1 Pre-Trained Network\n",
        "We will be using a network that is pretrained on the [FashionGen dataset](https://arxiv.org/abs/1806.08317). This dataset is comprised of people wearing different items of fashion.\n",
        "\n",
        "This network is trained to generate synthetic images (of size 64x64px) that look similar to the data distribution in the FashionGen dataset. If you are interested, you can look at the [DCGAN source code on GitHub](https://github.com/facebookresearch/pytorch_GAN_zoo/blob/master/models/DCGAN.py).\n",
        "\n",
        "In the code cell below, we download a pre-trained DCGAN model from the [PyTorch hub](https://pytorch.org/hub/). This size of this model is around 40MB, so it shouldn't take too long to download."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5326cba9-da39-4b48-9719-5b2d37f3a015",
      "metadata": {
        "id": "5326cba9-da39-4b48-9719-5b2d37f3a015"
      },
      "outputs": [],
      "source": [
        "dcgan = torch.hub.load('facebookresearch/pytorch_GAN_zoo:hub', 'DCGAN', pretrained=True, useGPU=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "831c9ac6-f14f-4a99-be1c-252a339c85f6",
      "metadata": {
        "id": "831c9ac6-f14f-4a99-be1c-252a339c85f6"
      },
      "source": [
        "## 2.2 Model Input"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90de3b19-2288-4545-97ca-20beb61d8612",
      "metadata": {
        "id": "90de3b19-2288-4545-97ca-20beb61d8612"
      },
      "source": [
        "Much like before, we need to feed this GAN random noise. To generate an image, this model requires a 120 dimensional vector. This model also has a method we can use to generate the vectors for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ba86da5-ffcc-41c3-800a-9ba64ba5f52c",
      "metadata": {
        "id": "9ba86da5-ffcc-41c3-800a-9ba64ba5f52c"
      },
      "outputs": [],
      "source": [
        "noise, _ = dcgan.buildNoiseData(n_samples=4)\n",
        "print(f'Shape of noise: {noise.shape}')\n",
        "print(f'Min/Max value of noise: {noise.min()}/{noise.max()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef32ad98-97f8-4183-bd0b-1989ab209ba0",
      "metadata": {
        "id": "ef32ad98-97f8-4183-bd0b-1989ab209ba0"
      },
      "source": [
        "## 2.3 Image Generation\n",
        "We generate images in the exact same way we did for PGAN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed3d1b3c-2818-4623-af48-4f48a7ccbd4c",
      "metadata": {
        "id": "ed3d1b3c-2818-4623-af48-4f48a7ccbd4c"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    generated_images = dcgan.test(noise)\n",
        "print(f'Shape of output: {generated_images.shape}')\n",
        "print(f'Min/Max value of output: {generated_images.min()}/{generated_images.max()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b42937b-4172-41ee-ab10-43b294c0f846",
      "metadata": {
        "id": "3b42937b-4172-41ee-ab10-43b294c0f846"
      },
      "source": [
        "## 2.4 Postprocessing and Visualization\n",
        "The postprocessing steps are also identical for PGAN!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b8731f1-4efc-4e06-af60-564b03ed0da3",
      "metadata": {
        "id": "3b8731f1-4efc-4e06-af60-564b03ed0da3"
      },
      "outputs": [],
      "source": [
        "for image_tensor in generated_images:\n",
        "    proc_image = postprocess_image(image_tensor)\n",
        "    display_image(proc_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d80d87e-f5dc-41e4-a677-914b52154f17",
      "metadata": {
        "id": "1d80d87e-f5dc-41e4-a677-914b52154f17"
      },
      "source": [
        "## 2.5 Pulling it Together\n",
        "Just like for PGAN, we were able to generate synthetic images resembling the dataset that DCGAN was trained on.\n",
        "\n",
        "Luckily for us, the interface to both PGAN and DCGAN was identical, allowing us to reuse the functions we wrote.\n",
        "\n",
        "In the code cell below we call the *`generate_images()`* function you wrote in section 1.5 with the DCGAN model to generate synthetic images. Run this cell a few times to see the different types of fashion images you can generate!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0980773c-b856-4fba-980a-08a9fafa1853",
      "metadata": {
        "id": "0980773c-b856-4fba-980a-08a9fafa1853"
      },
      "outputs": [],
      "source": [
        "generate_images(dcgan, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ae47b55-8136-4a34-a3aa-cdbcdc8fd28e",
      "metadata": {
        "id": "1ae47b55-8136-4a34-a3aa-cdbcdc8fd28e"
      },
      "source": [
        "## 2.6 Digging Deeper\n",
        "We can also visualize the impact of small perturbations on the random noise vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c178a5fa-df13-4d6f-ac5d-c5555f0c4666",
      "metadata": {
        "id": "c178a5fa-df13-4d6f-ac5d-c5555f0c4666"
      },
      "outputs": [],
      "source": [
        "# Set of perturbations to apply\n",
        "perturbations = [-0.2, -0.1, 0, 0.1, 0.2]\n",
        "\n",
        "# Generate random noise vector\n",
        "noise, _ = dcgan.buildNoiseData(n_samples=1)\n",
        "\n",
        "# Create a tensor combining perturbations\n",
        "noise_tensor = torch.cat([noise + pert for pert in perturbations], dim=0)\n",
        "\n",
        "# Perform forward pass\n",
        "with torch.no_grad():\n",
        "    generated_images = dcgan.test(noise_tensor)\n",
        "\n",
        "# Postprocess all images\n",
        "postprocessed_images = [postprocess_image(image_tensor) for image_tensor in generated_images]\n",
        "\n",
        "# Create a plot to display all images in a single row\n",
        "fig, axes = plt.subplots(nrows=1, ncols=len(perturbations), figsize=(19, 10))\n",
        "\n",
        "# Display images and set the titles to the perturbation applied\n",
        "for ax, image, pert in zip(axes, postprocessed_images, perturbations):\n",
        "    ax.imshow(image)\n",
        "    ax.set_title(pert)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a492d4d-d3c9-4699-8ade-7f452c970a5d",
      "metadata": {
        "id": "8a492d4d-d3c9-4699-8ade-7f452c970a5d"
      },
      "source": [
        "# Summary\n",
        "In this lab we used two different GAN architectures pretrained on different datasets to generate synthetic images. These images were generated from random noise, which is a very impressive feat! If you are interested in looking at other existing GAN architectures, you can take a look at [this GitHub repository](https://github.com/eriklindernoren/PyTorch-GAN) which has implementations of popular GANs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87abbc3a-2820-4841-bd32-8c19299fbac0",
      "metadata": {
        "id": "87abbc3a-2820-4841-bd32-8c19299fbac0"
      },
      "source": [
        "# Next Lab\n",
        "We will use Microsoft Azure for Image Classification inference"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}